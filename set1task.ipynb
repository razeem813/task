{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['OPENAI_API_KEY'] = \"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-31T06:31:35.731275Z","iopub.execute_input":"2023-03-31T06:31:35.732177Z","iopub.status.idle":"2023-03-31T06:31:35.768700Z","shell.execute_reply.started":"2023-03-31T06:31:35.732123Z","shell.execute_reply":"2023-03-31T06:31:35.767750Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install docx2txt","metadata":{"execution":{"iopub.status.busy":"2023-03-31T06:31:35.770832Z","iopub.execute_input":"2023-03-31T06:31:35.771219Z","iopub.status.idle":"2023-03-31T06:31:48.230613Z","shell.execute_reply.started":"2023-03-31T06:31:35.771173Z","shell.execute_reply":"2023-03-31T06:31:48.229279Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting docx2txt\n  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: docx2txt\n  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=7c2b95b47c8b0758fc04af7a73eebab25ac3cac3764dd166c3d5d36721db77c2\n  Stored in directory: /root/.cache/pip/wheels/08/45/4d/5985be6d2ead508294e8660bdf11c974153d1f519e96810d0c\nSuccessfully built docx2txt\nInstalling collected packages: docx2txt\nSuccessfully installed docx2txt-0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentence_transformers pinecone-client openai","metadata":{"execution":{"iopub.status.busy":"2023-03-31T06:31:48.233596Z","iopub.execute_input":"2023-03-31T06:31:48.234017Z","iopub.status.idle":"2023-03-31T06:32:01.034274Z","shell.execute_reply.started":"2023-03-31T06:31:48.233958Z","shell.execute_reply":"2023-03-31T06:32:01.032884Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pinecone-client\n  Downloading pinecone_client-2.2.1-py3-none-any.whl (177 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting openai\n  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.27.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.13.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.13.3)\nRequirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from pinecone-client) (1.26.14)\nRequirement already satisfied: pyyaml>=5.4 in /opt/conda/lib/python3.7/site-packages (from pinecone-client) (6.0)\nCollecting loguru>=0.5.0\n  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pinecone-client) (2.28.2)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from pinecone-client) (4.4.0)\nCollecting dnspython>=2.0.0\n  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.7/site-packages (from pinecone-client) (2.8.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.11.4)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pinecone-client) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.11.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence_transformers) (9.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.11.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=b67e6420f856bc52b7aa18b3384837f0ddc6a21629668f0615f50845bc4d1e73\n  Stored in directory: /root/.cache/pip/wheels/83/71/2b/40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\nSuccessfully built sentence_transformers\nInstalling collected packages: loguru, dnspython, pinecone-client, openai, sentence_transformers\nSuccessfully installed dnspython-2.3.0 loguru-0.6.0 openai-0.27.2 pinecone-client-2.2.1 sentence_transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#This is for embedding. In here, one LM model from huggingface used.\n\nfrom sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nMODEL = \"text-embedding-ada-002\"\nres = openai.Embedding.create(\n    input=[\"Sample document text goes here\"], engine=MODEL\n)\nt=\"abc\"\nprint(type(model.encode(t).tolist()))\nprint(type(res['data'][0]['embedding']))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:20:51.411133Z","iopub.execute_input":"2023-03-31T08:20:51.411836Z","iopub.status.idle":"2023-03-31T08:20:52.034690Z","shell.execute_reply.started":"2023-03-31T08:20:51.411796Z","shell.execute_reply":"2023-03-31T08:20:52.033629Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf861d7c418463586aed3278f1429d7"}},"metadata":{}},{"name":"stdout","text":"<class 'list'>\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"#Function to split long documents in to smaller parts\ndef split_text_into_chunks(plain_text, max_chars=2000):\n    text_chunks = []\n    current_chunk = \"\"\n    for line in plain_text.split(\"\\n\"):\n        if len(current_chunk) + len(line) + 1 <= max_chars:\n            current_chunk += line + \" \"\n        else:\n            text_chunks.append(current_chunk.strip())\n            current_chunk = line + \" \"\n    if current_chunk:\n        text_chunks.append(current_chunk.strip())\n    return text_chunks","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:20:52.950094Z","iopub.execute_input":"2023-03-31T08:20:52.951287Z","iopub.status.idle":"2023-03-31T08:20:52.958560Z","shell.execute_reply.started":"2023-03-31T08:20:52.951236Z","shell.execute_reply":"2023-03-31T08:20:52.957118Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import pinecone\npinecone.init(api_key=\"3a6fee7a-efe4-4755-8e5b-ac3af85abc3d\", environment=\"eu-west1-gcp\") #Todo: Initialization of vector database module\nindex = pinecone.Index(\"semantic-search-openai\") #Todo: Fill out with index name.","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:20:54.511298Z","iopub.execute_input":"2023-03-31T08:20:54.511690Z","iopub.status.idle":"2023-03-31T08:20:54.940924Z","shell.execute_reply.started":"2023-03-31T08:20:54.511635Z","shell.execute_reply":"2023-03-31T08:20:54.939925Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"index.describe_index_stats()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:20:57.187654Z","iopub.execute_input":"2023-03-31T08:20:57.188204Z","iopub.status.idle":"2023-03-31T08:20:57.615105Z","shell.execute_reply.started":"2023-03-31T08:20:57.188144Z","shell.execute_reply":"2023-03-31T08:20:57.614132Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {},\n 'total_vector_count': 0}"},"metadata":{}}]},{"cell_type":"code","source":"def addData(corpusData):\n    id  = index.describe_index_stats()['total_vector_count']\n    for i in range(len(corpusData)):\n        chunk=corpusData[i]\n        res=openai.Embedding.create(input=chunk, engine=MODEL)\n        chunkInfo=(str(id+i),\n                 res['data'][0]['embedding'], #We are using the model to encode the original chunk of text.\n                {'context': chunk}) #In metadata we are storing the original text here as context. \n        index.upsert(vectors=[chunkInfo])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:20:59.023690Z","iopub.execute_input":"2023-03-31T08:20:59.024506Z","iopub.status.idle":"2023-03-31T08:20:59.030972Z","shell.execute_reply.started":"2023-03-31T08:20:59.024465Z","shell.execute_reply":"2023-03-31T08:20:59.029923Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#This function is responsible for matching the input string with alread existing data on vector database.\n\ndef find_match(query,k):\n    query_em = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']\n    result = index.query(query_em, top_k=k, includeMetadata=True)\n    \n    return [result['matches'][i]['metadata']['context'] for i in range(k)]","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:00.130513Z","iopub.execute_input":"2023-03-31T08:21:00.130943Z","iopub.status.idle":"2023-03-31T08:21:00.142337Z","shell.execute_reply.started":"2023-03-31T08:21:00.130896Z","shell.execute_reply":"2023-03-31T08:21:00.141321Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import docx2txt\n\n# replace following line with location of your .docx file\nMY_TEXT = docx2txt.process(\"/kaggle/input/datalaw/DataLaw.docx\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:01.181715Z","iopub.execute_input":"2023-03-31T08:21:01.182462Z","iopub.status.idle":"2023-03-31T08:21:01.220980Z","shell.execute_reply.started":"2023-03-31T08:21:01.182416Z","shell.execute_reply":"2023-03-31T08:21:01.219921Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"splited_data=split_text_into_chunks(MY_TEXT, max_chars=2000)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:01.921848Z","iopub.execute_input":"2023-03-31T08:21:01.922538Z","iopub.status.idle":"2023-03-31T08:21:01.927976Z","shell.execute_reply.started":"2023-03-31T08:21:01.922496Z","shell.execute_reply":"2023-03-31T08:21:01.926908Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"len(splited_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:02.840276Z","iopub.execute_input":"2023-03-31T08:21:02.840631Z","iopub.status.idle":"2023-03-31T08:21:02.848921Z","shell.execute_reply.started":"2023-03-31T08:21:02.840598Z","shell.execute_reply":"2023-03-31T08:21:02.847502Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"29"},"metadata":{}}]},{"cell_type":"code","source":"addData(splited_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:03.961959Z","iopub.execute_input":"2023-03-31T08:21:03.964670Z","iopub.status.idle":"2023-03-31T08:21:15.750677Z","shell.execute_reply.started":"2023-03-31T08:21:03.964629Z","shell.execute_reply":"2023-03-31T08:21:15.749289Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"index.describe_index_stats()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:21.232812Z","iopub.execute_input":"2023-03-31T08:21:21.233216Z","iopub.status.idle":"2023-03-31T08:21:21.378128Z","shell.execute_reply.started":"2023-03-31T08:21:21.233178Z","shell.execute_reply":"2023-03-31T08:21:21.376950Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {'': {'vector_count': 29}},\n 'total_vector_count': 29}"},"metadata":{}}]},{"cell_type":"code","source":"def create_prompt(context,query):\n    header = \"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text and requires some latest information to be updated, print 'Sorry Not Sufficient context to answer query' \\n\"\n    return header + context + query + \"\\n\"","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:21:27.832066Z","iopub.execute_input":"2023-03-31T08:21:27.832437Z","iopub.status.idle":"2023-03-31T08:21:27.837985Z","shell.execute_reply.started":"2023-03-31T08:21:27.832402Z","shell.execute_reply":"2023-03-31T08:21:27.836947Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"import openai\nimport pandas as pd\nscore=[]\ncontext=[]\nopenai.api_key=\"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\"\ndef generate_answer(prompt):\n    response = openai.Embedding.create(\n    input= prompt,\n    model=\"text-embedding-ada-002\"\n    )\n    res1= response['data'][0]['embedding']\n    res = index.query([res1], top_k=2, include_metadata=True)\n    for match in res['matches']:\n        score.append(match['score'])\n        context.append(match['metadata']['context'])\n    df = pd.DataFrame(\n    {'score': score,\n     'context': context \n    })\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T09:39:33.095259Z","iopub.execute_input":"2023-03-31T09:39:33.095639Z","iopub.status.idle":"2023-03-31T09:39:33.105278Z","shell.execute_reply.started":"2023-03-31T09:39:33.095604Z","shell.execute_reply":"2023-03-31T09:39:33.104173Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"def user_query(query):\n    docs,res = find_match(query,2)\n    prompt = create_prompt(res,query)\n    reply = generate_answer(prompt)\n    print(reply)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T09:39:33.552967Z","iopub.execute_input":"2023-03-31T09:39:33.553738Z","iopub.status.idle":"2023-03-31T09:39:33.559118Z","shell.execute_reply.started":"2023-03-31T09:39:33.553695Z","shell.execute_reply":"2023-03-31T09:39:33.557955Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"user_query(\"what is long distance pipelines?\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T09:39:34.202268Z","iopub.execute_input":"2023-03-31T09:39:34.202937Z","iopub.status.idle":"2023-03-31T09:39:35.700194Z","shell.execute_reply.started":"2023-03-31T09:39:34.202899Z","shell.execute_reply":"2023-03-31T09:39:35.698967Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"      score                                            context\n0  0.936061  Notwithstanding the provisions of paragraph on...\n1  0.879805  -  long distance pipelines, long distance (bac...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Suggestion for improvement devinci 003\ntext-davinci-003 includes the following improvements: It produces higher quality writing. This will help your applications deliver clearer, more engaging, and more compelling content. It can handle more complex instructions, meaning you can get even more creative with how you make use of its capabilities now.","metadata":{}},{"cell_type":"code","source":"def generate_answer1(prompt):\n    response = openai.Completion.create(\n    model=\"text-davinci-003\",\n    prompt=prompt,\n    temperature=0,\n    max_tokens=256,\n    top_p=1,\n    frequency_penalty=0,\n    presence_penalty=0,\n    stop = [' END']\n    )\n    return (response.choices[0].text).strip()\n     ","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:51:57.512597Z","iopub.execute_input":"2023-03-31T08:51:57.513733Z","iopub.status.idle":"2023-03-31T08:51:57.520448Z","shell.execute_reply.started":"2023-03-31T08:51:57.513689Z","shell.execute_reply":"2023-03-31T08:51:57.519310Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"def user_query1(query):\n    docs,res = find_match(query,2)\n    prompt = create_prompt(res,query)\n    reply = generate_answer1(prompt)\n    print(reply)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:51:58.039706Z","iopub.execute_input":"2023-03-31T08:51:58.040384Z","iopub.status.idle":"2023-03-31T08:51:58.046872Z","shell.execute_reply.started":"2023-03-31T08:51:58.040348Z","shell.execute_reply":"2023-03-31T08:51:58.044858Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"user_query1(\"what is pipeline?\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T08:52:03.495693Z","iopub.execute_input":"2023-03-31T08:52:03.496422Z","iopub.status.idle":"2023-03-31T08:52:04.961510Z","shell.execute_reply.started":"2023-03-31T08:52:03.496383Z","shell.execute_reply":"2023-03-31T08:52:04.960313Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"Pipeline is a long, large diameter pipe used to transport products such as oil, natural gas, or water over long distances.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Task2","metadata":{}},{"cell_type":"code","source":"print('Do you go out to party on weekends? (yes or no)')\nx = input()\nprint('What flavours do you like? (cider, sweet, waterlike)')\ny = input()\nprint('What texture you don not like? (smooth, slimy, rough)')\nz = input()\nprint('What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)')\na = input()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T13:13:22.030708Z","iopub.execute_input":"2023-03-31T13:13:22.031079Z","iopub.status.idle":"2023-03-31T13:13:40.014101Z","shell.execute_reply.started":"2023-03-31T13:13:22.031046Z","shell.execute_reply":"2023-03-31T13:13:40.013138Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Do you go out to party on weekends? (yes or no)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" yes\n"},{"name":"stdout","text":"What flavours do you like? (cider, sweet, waterlike)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" cider\n"},{"name":"stdout","text":"What texture you don not like? (smooth, slimy, rough)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" smooth\n"},{"name":"stdout","text":"What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" 5\n"}]},{"cell_type":"code","source":"prompt = x + \"go to party.\" + \"I like \" + y + z + \"texture don't like.\" + a + \"will be the price range\"\nprint(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T13:13:42.342645Z","iopub.execute_input":"2023-03-31T13:13:42.343345Z","iopub.status.idle":"2023-03-31T13:13:42.348772Z","shell.execute_reply.started":"2023-03-31T13:13:42.343305Z","shell.execute_reply":"2023-03-31T13:13:42.347662Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"yesgo to party.I like cidersmoothtexture don't like.5will be the price range\n","output_type":"stream"}]},{"cell_type":"code","source":"# Authenticate with the OpenAI API\nopenai.api_key = \"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\"\n\ndoclist=[\"If they party on weekends, apples, pears, grapes, watermelon are allowed.\",\n\"If they like cider, show apples, oranges, lemon, lime.\",\n\"If they like sweet, show watermelon, orange.\",\n\"If they like waterlike, show watermelon.\",\n\"If grapes is chosen, remove watermelon from the list.\",\n\"If texture you don't like is smooth, remove pears.\",\n\"If texture you don't like is slimy, remove watermelon, lime and grape.\",\n\"If texture you don't like is waterlike, remove watermelon.\",\n\"If price < $3 remove lime, watermelon.\",\n\"If price > $4 and < $7 remove pears, apples.\"]\n\ndef generate_answer2(prompt):\n    response = openai.Completion.create(\n    model=\"text-davinci-003\",\n    prompt=prompt,\n    document=doclist,    \n    temperature=0,\n    max_tokens=256,\n    top_p=1,\n    frequency_penalty=0,\n    presence_penalty=0,\n    stop = [' END']\n    )\n    return (response.choices[0].text).strip()\n     \n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T06:35:58.913570Z","iopub.status.idle":"2023-03-31T06:35:58.914719Z","shell.execute_reply.started":"2023-03-31T06:35:58.914451Z","shell.execute_reply":"2023-03-31T06:35:58.914479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}