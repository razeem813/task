{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai gpt","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:24.808741Z","iopub.execute_input":"2023-03-31T14:06:24.809063Z","iopub.status.idle":"2023-03-31T14:06:38.286923Z","shell.execute_reply.started":"2023-03-31T14:06:24.809032Z","shell.execute_reply":"2023-03-31T14:06:38.285702Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gpt\n  Downloading gpt-0.2-py3-none-any.whl (18 kB)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: gpt, openai\nSuccessfully installed gpt-0.2 openai-0.27.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport openai\nimport uuid\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.289311Z","iopub.execute_input":"2023-03-31T14:06:38.290039Z","iopub.status.idle":"2023-03-31T14:06:38.489701Z","shell.execute_reply.started":"2023-03-31T14:06:38.289993Z","shell.execute_reply":"2023-03-31T14:06:38.488550Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"openai.api_key=\"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\"","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.491024Z","iopub.execute_input":"2023-03-31T14:06:38.491940Z","iopub.status.idle":"2023-03-31T14:06:38.498045Z","shell.execute_reply.started":"2023-03-31T14:06:38.491897Z","shell.execute_reply":"2023-03-31T14:06:38.496889Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Example:\n\n   # Stores an input, output pair and formats it to prime the model\n   def __init__(self, input, output):\n       self.input = input\n       self.output = output\n       self.id = uuid.uuid4().hex\n\n   # To obtain the input provided for an example\n   def get_input(self):\n       return self.input\n\n   # To obtain the output provided for an example\n   def get_output(self):\n       return self.output\n\n   # To obtain the unique id of an example\n   def get_id(self):\n       return self.id","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.501330Z","iopub.execute_input":"2023-03-31T14:06:38.502371Z","iopub.status.idle":"2023-03-31T14:06:38.509745Z","shell.execute_reply.started":"2023-03-31T14:06:38.502167Z","shell.execute_reply":"2023-03-31T14:06:38.508581Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class GPT3:\n\n   \"\"\"\n      Params engine: Model to be used. Options are Davinci, Babbage, Ada and Curie.\n      temperature: Amount of randomness to be introduced in the predictions of the\n      model Setting a higher value of temperature would be useful for creative \n      applications whereas a lower value will be suitable for well defined answers.\n      max_tokens: Maximum length of number of tokens accepted by the prompt.\n   \"\"\"\n\n   # initialises parameters and adds default values\n   def __init__(self, engine='davinci', temperature=0.5, max_tokens=100,\n\n       input_prefix=\"input: \", input_suffix=\"\\n\", output_prefix=\"output: \",\n       output_suffix=\"\\n\\n\", append_output_prefix_to_query=False):\n       self.examples = {}\n       self.engine = engine\n       self.temperature = temperature\n       self.max_tokens = max_tokens\n       self.input_prefix = input_prefix\n       self.input_suffix = input_suffix\n       self.output_prefix = output_prefix\n       self.output_suffix = output_suffix\n       self.append_output_prefix_to_query = append_output_prefix_to_query\n       self.stop = (output_suffix + input_prefix).strip()\n\n   # Adds an example to the model object. Example is an instance of the Example class.\n   def add_example(self, ex):\n       assert isinstance(ex, Example), \"Please create an Example object.\"\n       self.examples[ex.get_id()] = ex\n\n   # Converts all the examples to a particular format to prime the model.\n   def get_prime_text(self):\n       return \"\".join(\n           [self.format_example(ex) for ex in self.examples.values()])\n\n   # Creates a query for the API request\n   def craft_query(self, prompt):\n       q = self.get_prime_text(\n       ) + self.input_prefix + prompt + self.input_suffix\n\n       if self.append_output_prefix_to_query:\n           q = q + self.output_prefix\n       return q\n\n   # Calls the API using the Completion endpoint with the specified values of the parameters\n   def submit_request(self, prompt):\n       response = openai.Completion.create(engine=self.engine,\n                                           prompt=self.craft_query(prompt),\n                                           max_tokens=self.max_tokens,\n                                           temperature=self.temperature,\n                                           top_p=1,\n                                           n=1,\n                                           stream=False,\n                                           stop=self.stop)\n       return response\n\n   # Formats the input output pair with appropriate prefixes and suffixes\n   def format_example(self, ex):\n       return self.input_prefix + ex.get_input(\n       ) + self.input_suffix + self.output_prefix + ex.get_output(\n       ) + self.output_suffix","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.511287Z","iopub.execute_input":"2023-03-31T14:06:38.512169Z","iopub.status.idle":"2023-03-31T14:06:38.525298Z","shell.execute_reply.started":"2023-03-31T14:06:38.512137Z","shell.execute_reply":"2023-03-31T14:06:38.524279Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"gpt3 = GPT3(engine=\"davinci\", temperature=0.5, max_tokens=100)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.527615Z","iopub.execute_input":"2023-03-31T14:06:38.528482Z","iopub.status.idle":"2023-03-31T14:06:38.536300Z","shell.execute_reply.started":"2023-03-31T14:06:38.528444Z","shell.execute_reply":"2023-03-31T14:06:38.535021Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"gpt3.add_example(Example('If they party on weekends.','apples, pears, grapes, watermelon are allowed.'))\n\ngpt3.add_example(Example(\"If they like cider\",\"show apples, oranges, lemon, lime.\"))\n\ngpt3.add_example(Example(\"If they like sweet.\",\"show watermelon, orange.\"))\n\ngpt3.add_example(Example(\"If they like waterlike\",\"show watermelon.\"))\n\ngpt3.add_example(Example(\"If grapes is chosen\",\"remove watermelon from the list.\"))\n\ngpt3.add_example(Example(\"If texture you don't like is smooth,\",\"remove pears.\"))\n\ngpt3.add_example(Example(\"If texture you don't like is slimy,\",'remove watermelon, lime and grape.'))\n\ngpt3.add_example(Example(\"If texture you don't like is waterlike,\",'remove watermelon.'))\n\ngpt3.add_example(Example(\"If price < $3 remove lime,\",'watermelon.'))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.538116Z","iopub.execute_input":"2023-03-31T14:06:38.538491Z","iopub.status.idle":"2023-03-31T14:06:38.548627Z","shell.execute_reply.started":"2023-03-31T14:06:38.538451Z","shell.execute_reply":"2023-03-31T14:06:38.547503Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print('Do you go out to party on weekends? (yes or no)')\nx = input()\nprint('What flavours do you like? (cider, sweet, waterlike)')\ny = input()\nprint('What texture you don not like? (smooth, slimy, rough)')\nz = input()\nprint('What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)')\na = input()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:06:38.550544Z","iopub.execute_input":"2023-03-31T14:06:38.550935Z","iopub.status.idle":"2023-03-31T14:07:05.835950Z","shell.execute_reply.started":"2023-03-31T14:06:38.550898Z","shell.execute_reply":"2023-03-31T14:07:05.834926Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Do you go out to party on weekends? (yes or no)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" no\n"},{"name":"stdout","text":"What flavours do you like? (cider, sweet, waterlike)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" sweet\n"},{"name":"stdout","text":"What texture you don not like? (smooth, slimy, rough)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" slimy\n"},{"name":"stdout","text":"What price range will you buy drink for? ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" $4\n"}]},{"cell_type":"code","source":"prompt = x + \" go to party.\" + \"I like \" + y+\".\"+  z + \" texture don't like. \" + a + \" will be the price range \"\nprint(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:07:05.837353Z","iopub.execute_input":"2023-03-31T14:07:05.837832Z","iopub.status.idle":"2023-03-31T14:07:05.845536Z","shell.execute_reply.started":"2023-03-31T14:07:05.837791Z","shell.execute_reply":"2023-03-31T14:07:05.844432Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"no go to party.I like sweet.slimy texture don't like. $4 will be the price range \n","output_type":"stream"}]},{"cell_type":"code","source":"type(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:07:05.849848Z","iopub.execute_input":"2023-03-31T14:07:05.850210Z","iopub.status.idle":"2023-03-31T14:07:05.865430Z","shell.execute_reply.started":"2023-03-31T14:07:05.850174Z","shell.execute_reply":"2023-03-31T14:07:05.864346Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}]},{"cell_type":"code","source":"response = gpt3.submit_request(str(prompt))\nresponse.choices[0].text #This chooses the topmost response from multiple outputs if any. ","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:07:05.867395Z","iopub.execute_input":"2023-03-31T14:07:05.867787Z","iopub.status.idle":"2023-03-31T14:07:07.259545Z","shell.execute_reply.started":"2023-03-31T14:07:05.867750Z","shell.execute_reply":"2023-03-31T14:07:07.258300Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'output: show oranges, watermelon, apples, pears.\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install Flask Flask-RESTful\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:07:07.261475Z","iopub.execute_input":"2023-03-31T14:07:07.261892Z","iopub.status.idle":"2023-03-31T14:07:17.653019Z","shell.execute_reply.started":"2023-03-31T14:07:07.261835Z","shell.execute_reply":"2023-03-31T14:07:17.651748Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: Flask in /opt/conda/lib/python3.7/site-packages (2.2.3)\nCollecting Flask-RESTful\n  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: click>=8.0 in /opt/conda/lib/python3.7/site-packages (from Flask) (8.1.3)\nRequirement already satisfied: Werkzeug>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from Flask) (2.2.3)\nRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask) (2.1.2)\nRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flask) (3.1.2)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from Flask) (4.11.4)\nRequirement already satisfied: six>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from Flask-RESTful) (1.16.0)\nCollecting aniso8601>=0.82\n  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from Flask-RESTful) (2023.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask) (4.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->Flask) (2.1.1)\nInstalling collected packages: aniso8601, Flask-RESTful\nSuccessfully installed Flask-RESTful-0.3.9 aniso8601-9.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# encoding: utf-8\nimport json\nfrom flask import Flask\napp = Flask(__name__)\n@app.route('/')\ndef index():\n    return json.dumps({'output': response.choices[0].text})\napp.run()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T14:10:26.780308Z","iopub.execute_input":"2023-03-31T14:10:26.781412Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}